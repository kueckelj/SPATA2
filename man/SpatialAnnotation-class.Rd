% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/S4-documentation.R
\docType{class}
\name{SpatialAnnotation-class}
\alias{SpatialAnnotation-class}
\alias{SpatialAnnotation}
\title{The \code{SpatialAnnotation} - Class}
\description{
S4 class that represents annotations for spatial data,
allowing users to define and store polygons that outline areas of interest
within images or datasets. It serves as the overarching class for different
spatial annotation methods.
}
\details{
The following classes are derivatives of this class: \code{\link{GroupAnnotation}},
\code{\link{ImageAnnotation}}, \code{\link{NumericAnnotation}}
}
\section{Slots}{

\describe{
\item{\code{area}}{list. A named list of data.frames with the numeric variables \emph{x_orig} and \emph{y_orig}.
Observations correspond to the vertices of the polygons that are needed to represent the
spatial annotation. \strong{Must} contain a slot named \emph{outer} which sets the outer border
of the spatial annotation. \strong{Can} contain multiple slots named \emph{inner} (suffixed)
with numbers that correspond to inner polygons - holes within the annotation.

Upon extraction via \code{\link[=getSpatAnnOutlineDf]{getSpatAnnOutlineDf()}} or extraction of the whole annotation
via \code{\link[=getSpatialAnnotation]{getSpatialAnnotation()}} and \code{\link[=getSpatialAnnotations]{getSpatialAnnotations()}} the variables \emph{x} and \emph{y}
are created by scaling \emph{x_orig} and \emph{y_orig} to the current resolution of the
active image to ensure alignment. This is achieved by using the \emph{coords} scale factor
of the listslot @scale_factors of the \code{\link{HistoImage}} object of the active image.}

\item{\code{id}}{character. String to identify the object in a list of multiple objects
of the same class.}

\item{\code{image}}{A cropped version of an image that focuses solely on the area containing the
annotation, along with an expansion margin. This slot is designed to remain
empty until the annotation object is explicitly extracted or used, contributing to efficient
data storage. Extraction through functions like \code{\link[=getSpatialAnnotation]{getSpatialAnnotation()}} or
\code{\link[=getSpatialAnnotation]{getSpatialAnnotation()}} populates this slot with the cropped image. The parameters
used for cropping the image are stored in the \verb{@image_info} slot.}

\item{\code{image_info}}{A list containing information related to the image stored in the @image slot.
This information pertains to the cropped image obtained and set using functions like
\code{\link[=getSpatialAnnotation]{getSpatialAnnotation()}} or \code{\link[=getSpatialAnnotations]{getSpatialAnnotations()}}. It serves as metadata
around the cropped image and may include parameters or details about the cropping process.}

\item{\code{misc}}{list. A flexible list for miscellaneous input such as meta data
or to implement new ideas..}

\item{\code{sample}}{Character string. The sample to which the annotation belongs.}

\item{\code{tags}}{character. Vector of arbitrary length. Contains tags that can be used
to group and select spatial annotations in different manners.}

\item{\code{version}}{A list of three slots denoting the version of \code{SPATA2} under
which the object has been created.}
}}

\section{Selection of spatial annotations}{


Selection of spatial annotations via the arguments \code{ids}, \code{class}, \code{tags} and
\code{test} works in three steps:

First, if \code{ids} is a character it prefilters the annotations by ID and only
the specified ones are submitted to the next steps. If it is \code{NULL}, all
annotations are submitted to the next steps.

Secondd, if \code{class} is a character it filters the annotations remaining
after the first step by their class. If \code{NULL}, the step is skipped.

Third, if \code{tags} is a character it is used in combination with \code{test} to select
from the spatial annotations that remain after the second step based on the meta data
they are tagged with. There are multiple options:
\enumerate{
\item Argument \code{test} set to \emph{'any'} or \emph{1}: To be included, an image annotation
must be tagged with at least one of the input tags.
\item Argument \code{test} set to \emph{'all'} or \emph{2}: To be included, an image annotation
must be tagged with all of the input tags. Can contain tags that are not specified.
\item Argument \code{test} set to \emph{'identical'} or \emph{3}: To be included, an image annotation
must be tagged with all of the input tags. Can not be tagged with anything else.
\item Argument \code{test} set to \emph{not_identical} or \emph{4}: To be included, an image
annotation must \strong{not} be tagged with the combination of input tags.
\item Argument \code{test} set to \emph{'none'} or \emph{5}: To be included, an image annotation
must \strong{not} contain any of the input tags.
}

If \code{tags} is \code{NULL}, the step is skipped. Therefore, if \code{ids}, \code{class} and \code{tags}
are all NULL, which is the default, all annotations are selected as all subsetting
steps are skipped. Eventually, the remaining spatial annotations are submitted to
whatever the respective function does.
}

\seealso{
The following functions can be used to create spatial annotations:

\itemize{
\item{\code{\link[=addSpatialAnnotation]{addSpatialAnnotation()}}:}{ Based on polygon input.}
\item{\code{\link[=barcodesToSpatialAnnotation]{barcodesToSpatialAnnotation()}}:}{Based on the spatial extent of a
set of data points identified by the input barcodes.}
\item{\code{\link[=createGroupAnnotations]{createGroupAnnotations()}}:}{ Based on the spatial extent of one or more
groups of data points. Uses \code{barcodesToSpatialAnnotation()}}
\item{\code{\link[=createImageAnnotations]{createImageAnnotations()}}:}{ Based on interactive drawing
on images.}
\item{\code{\link[=createNumericAnnotations]{createNumericAnnotations()}}:}{ Based on the expression of numeric
features such as gene expression, read counts, copy number alterations, etc.
Uses \code{\link[=barcodesToSpatialAnnotation]{barcodesToSpatialAnnotation()}}}
}
}
